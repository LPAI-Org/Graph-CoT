{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pay attention to the reproducibility !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=f\"/shared/data3/bowenj4/llm-graph-plugin/data/processed_data/amazon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['item_nodes', 'brand_nodes'])\n"
     ]
    }
   ],
   "source": [
    "# read processed graph\n",
    "import json \n",
    "graph = json.load(open(os.path.join(data_dir, 'graph.json')))\n",
    "print(graph.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_generated_data = {} # key: triple (question (str), answer (str)), value: generated data (List)\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design questions (one type of question in one cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-hop reasoning (easy)\n",
    "# What is the brand of item xxx?\n",
    "# What is the price of item xxx?\n",
    "# What is the category of item xxx?\n",
    "\n",
    "random.seed(2023)\n",
    "item_ids = list(graph['item_nodes'].keys()) # 9430088\n",
    "\n",
    "question = \"What is the brand of item {item_title}?\"\n",
    "answer = \"{brand_name}\"\n",
    "generated_data = []\n",
    "random.shuffle(item_ids)\n",
    "for item_id in item_ids:\n",
    "    item_title = graph['item_nodes'][item_id]['features']['title']\n",
    "    brand_ids = graph['item_nodes'][item_id]['neighbors']['brand']\n",
    "\n",
    "    if len(brand_ids) != 1:\n",
    "        continue\n",
    "\n",
    "    brand_names = [graph['brand_nodes'][brand_id]['features']['name'] for brand_id in brand_ids]\n",
    "    if len(brand_names)>0 and item_title!='':\n",
    "        generated_data.append({\"item_title\":item_title, \"brand_name\": ', '.join(brand_names)})\n",
    "    if len(generated_data)==k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2024)\n",
    "question = \"What is the category of item {item_title}?\"\n",
    "answer = \"{category}\"\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "\n",
    "generated_data = []\n",
    "random.shuffle(item_ids)\n",
    "for item_id in item_ids:\n",
    "    item_title = graph['item_nodes'][item_id]['features']['title']\n",
    "    category = graph['item_nodes'][item_id]['features']['category']\n",
    "\n",
    "    if len(category) != 1:\n",
    "        continue\n",
    "\n",
    "    if item_title!='':\n",
    "        generated_data.append({\"item_title\":item_title, \"category\":', '.join(category)})\n",
    "    if len(generated_data)==k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2025)\n",
    "\n",
    "question = \"What is the price of item {item_title}?\"\n",
    "answer = \"{price}\"\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "\n",
    "generated_data = []\n",
    "random.shuffle(item_ids)\n",
    "for item_id in item_ids:\n",
    "    item_title = graph['item_nodes'][item_id]['features']['title']\n",
    "    price = graph['item_nodes'][item_id]['features']['price']\n",
    "    \n",
    "    if price!='' and item_title!='':\n",
    "        generated_data.append({\"item_title\":item_title, \"price\":price})\n",
    "    if len(generated_data)==k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree-based reasoning (easy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### How many “co-viewed” items does item xxx have?\n",
    "##### How many “co-purchased” items does item xxx have? # TODO ambiguous question?\n",
    "##### How many items are in brand xxx?\n",
    "\n",
    "random.seed(2026)\n",
    "\n",
    "question = \"How many co-viewed items does item {item_title} have?\"\n",
    "answer = \"{num}\"\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "\n",
    "generated_data = []\n",
    "random.shuffle(item_ids)\n",
    "for item_id in item_ids:\n",
    "    item_title = graph['item_nodes'][item_id]['features']['title']\n",
    "    related_item_ids = graph['item_nodes'][item_id]['neighbors']['also_viewed_item']\n",
    "    \n",
    "    if item_title!='':\n",
    "        generated_data.append({\"item_title\":item_title, \"num\": len(related_item_ids)})\n",
    "    if len(generated_data)==k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2027)\n",
    "\n",
    "question = \"How many bought-together items does item {item_title} have?\"\n",
    "answer = \"{num}\"\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "\n",
    "generated_data = []\n",
    "random.shuffle(item_ids)\n",
    "for item_id in item_ids:\n",
    "    item_title = graph['item_nodes'][item_id]['features']['title']\n",
    "    related_item_ids = graph['item_nodes'][item_id]['neighbors']['bought_together_item']\n",
    "    if item_title!='':\n",
    "        generated_data.append({\"item_title\":item_title, \"num\": len(related_item_ids)})\n",
    "    if len(generated_data)==k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2028)\n",
    "\n",
    "question = \"How many buy-after-viewing items does item {item_title} have?\"\n",
    "answer = \"{num}\"\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "\n",
    "generated_data = []\n",
    "random.shuffle(item_ids)\n",
    "for item_id in item_ids:\n",
    "    item_title = graph['item_nodes'][item_id]['features']['title']\n",
    "    related_item_ids = graph['item_nodes'][item_id]['neighbors']['buy_after_viewing_item']\n",
    "    if item_title!='':\n",
    "        generated_data.append({\"item_title\":item_title, \"num\": len(related_item_ids)})\n",
    "    if len(generated_data)==k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2029)\n",
    "\n",
    "question = \"How many also-bought items does item {item_title} have?\"\n",
    "answer = \"{num}\"\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "\n",
    "generated_data = []\n",
    "random.shuffle(item_ids)\n",
    "for item_id in item_ids:\n",
    "    item_title = graph['item_nodes'][item_id]['features']['title']\n",
    "    related_item_ids = graph['item_nodes'][item_id]['neighbors']['also_bought_item']\n",
    "    if item_title!='':\n",
    "        generated_data.append({\"item_title\":item_title, \"num\": len(related_item_ids)})\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "    \n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2030)\n",
    "\n",
    "question = \"How many items are in brand {brand_name}?\"\n",
    "answer = \"{num}\"\n",
    "generated_data = []\n",
    "\n",
    "brand_ids = list(graph['brand_nodes'].keys()) # 110796\n",
    "random.shuffle(brand_ids)\n",
    "\n",
    "for brand_id in brand_ids:\n",
    "    brand_name = graph['brand_nodes'][brand_id]['features']['name']\n",
    "    within_item_ids = graph['brand_nodes'][brand_id]['neighbors']['item']\n",
    "    if brand_name!='':\n",
    "        generated_data.append({\"brand_name\":brand_name, \"num\": len(within_item_ids)})\n",
    "    if len(generated_data)==k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-hop reasoning (medium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2031)\n",
    "\n",
    "question = \"Find the items which are in the same brand and same category as item {item_title}.\"\n",
    "answer = \"{item_title_neighbour}\"\n",
    "\n",
    "generated_data = []\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "random.shuffle(item_ids)\n",
    "brand_ids = list(graph['brand_nodes'].keys()) # 110796\n",
    "random.shuffle(brand_ids)\n",
    "\n",
    "for item_id in item_ids:\n",
    "    item_features = graph['item_nodes'][item_id]['features']\n",
    "    item_title = item_features['title']\n",
    "    if item_title == '':\n",
    "        continue\n",
    "    brand_ids = graph['item_nodes'][item_id]['neighbors']['brand']\n",
    "    if len(brand_ids) != 1:\n",
    "        continue\n",
    "\n",
    "    brand_id = brand_ids[0]  # search for same brand, just use the first brand\n",
    "    within_item_ids = graph['brand_nodes'][brand_id]['neighbors']['item']\n",
    "    result_list = []\n",
    "    for within_item_id in within_item_ids: \n",
    "        if within_item_id==item_id:\n",
    "            continue\n",
    "        neighbor_features = graph['item_nodes'][within_item_id]['features']\n",
    "        neighbor_categories = neighbor_features['category']\n",
    "        if len(neighbor_categories)==0:\n",
    "            continue\n",
    "        neighbor_category = neighbor_categories[0]  # search for same category, just use the first category\n",
    "        if neighbor_category in item_features['category']: \n",
    "            result_list.append(neighbor_features['title'])\n",
    "            #generated_data.append({\"item_title\":item_title, \"item_title_neighbour\":neighbor_features['title']})\n",
    "            #break\n",
    "\n",
    "    if len(result_list) < 20 and len(result_list) > 0:\n",
    "        generated_data.append({\"item_title\":item_title, \"item_title_neighbour\": ', '.join(result_list)})\n",
    "\n",
    "    if len(generated_data)==k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 283248/9430088 [00:01<00:51, 177475.41it/s]\n",
      " 72%|███████▏  | 6822990/9430088 [00:24<00:09, 278025.97it/s]\n",
      " 14%|█▍        | 1328009/9430088 [00:04<00:25, 322740.77it/s]\n",
      " 91%|█████████ | 8581565/9430088 [00:25<00:02, 330355.67it/s]\n",
      "  4%|▍         | 413145/9430088 [00:01<00:29, 301051.18it/s]\n",
      "  4%|▍         | 420765/9430088 [00:01<00:28, 319062.84it/s]\n",
      " 41%|████▏     | 3908380/9430088 [00:12<00:17, 321275.80it/s]\n",
      " 36%|███▌      | 3409239/9430088 [00:10<00:18, 318776.58it/s]\n",
      "  9%|▊         | 804030/9430088 [00:02<00:27, 319014.98it/s]\n",
      "100%|██████████| 9430088/9430088 [00:26<00:00, 360472.84it/s]\n",
      " 52%|█████▏    | 4887762/9430088 [00:13<00:12, 349841.18it/s]\n",
      " 51%|█████▏    | 4850786/9430088 [00:12<00:12, 378639.81it/s]\n",
      "  5%|▍         | 430062/9430088 [00:01<00:28, 315121.03it/s]\n",
      "  5%|▌         | 498277/9430088 [00:01<00:25, 344238.43it/s]\n",
      " 28%|██▊       | 2645891/9430088 [00:08<00:20, 327886.52it/s]\n",
      "  8%|▊         | 759418/9430088 [00:02<00:26, 322402.37it/s]\n",
      " 52%|█████▏    | 4912677/9430088 [00:14<00:13, 338047.48it/s]\n",
      "  6%|▌         | 582228/9430088 [00:01<00:27, 319313.07it/s]\n",
      " 16%|█▌        | 1525204/9430088 [00:04<00:24, 318666.73it/s]\n",
      "  2%|▏         | 163108/9430088 [00:00<00:31, 296691.21it/s]\n",
      "  3%|▎         | 315911/9430088 [00:00<00:28, 324922.89it/s]\n",
      " 18%|█▊        | 1677625/9430088 [00:05<00:23, 328987.84it/s]\n",
      " 22%|██▏       | 2040148/9430088 [00:05<00:20, 359903.99it/s]\n",
      " 12%|█▏        | 1091613/9430088 [00:03<00:30, 273171.35it/s]\n",
      " 20%|█▉        | 1858480/9430088 [00:06<00:24, 307616.60it/s]\n",
      " 13%|█▎        | 1220393/9430088 [00:03<00:23, 347937.97it/s]\n",
      "  5%|▍         | 463416/9430088 [00:01<00:27, 330378.67it/s]\n",
      "  6%|▌         | 535689/9430088 [00:01<00:26, 333045.99it/s]\n",
      " 21%|██▏       | 2013279/9430088 [00:05<00:20, 356105.01it/s]\n",
      "  8%|▊         | 772208/9430088 [00:02<00:27, 318138.93it/s]\n",
      "  5%|▌         | 516442/9430088 [00:01<00:27, 324555.58it/s]\n",
      "100%|██████████| 9430088/9430088 [00:27<00:00, 339653.01it/s]\n",
      " 34%|███▍      | 3203160/9430088 [00:09<00:19, 326064.95it/s]\n",
      "100%|██████████| 9430088/9430088 [00:25<00:00, 370176.12it/s]\n",
      "  5%|▌         | 512812/9430088 [00:01<00:27, 324225.03it/s]\n",
      " 18%|█▊        | 1655076/9430088 [00:04<00:22, 339353.27it/s]\n",
      " 10%|▉         | 931537/9430088 [00:02<00:25, 328979.25it/s]\n",
      " 16%|█▌        | 1466814/9430088 [00:04<00:22, 357439.55it/s]\n",
      " 14%|█▎        | 1289517/9430088 [00:03<00:23, 340751.10it/s]\n",
      " 24%|██▍       | 2246883/9430088 [00:06<00:20, 354113.88it/s]\n",
      " 20%|█▉        | 1846316/9430088 [00:05<00:21, 351465.63it/s]\n",
      " 34%|███▎      | 3181514/9430088 [00:09<00:19, 326925.43it/s]\n",
      "  9%|▉         | 890941/9430088 [00:02<00:26, 324807.66it/s]\n",
      " 97%|█████████▋| 9184517/9430088 [00:25<00:00, 362061.81it/s]\n",
      "100%|██████████| 9430088/9430088 [00:25<00:00, 377071.24it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 385139.94it/s]\n",
      "100%|██████████| 9430088/9430088 [00:27<00:00, 339559.31it/s]\n",
      " 23%|██▎       | 2205037/9430088 [00:05<00:19, 371064.05it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 379849.14it/s]\n",
      " 55%|█████▌    | 5195830/9430088 [00:13<00:11, 373574.76it/s]\n",
      "  7%|▋         | 685053/9430088 [00:02<00:30, 287043.60it/s]\n",
      "100%|██████████| 9430088/9430088 [00:25<00:00, 371865.77it/s]\n",
      " 14%|█▍        | 1329327/9430088 [00:04<00:25, 319574.22it/s]\n",
      " 10%|▉         | 898367/9430088 [00:02<00:22, 376639.87it/s]\n",
      "  7%|▋         | 667758/9430088 [00:02<00:29, 292430.60it/s]\n",
      "  1%|▏         | 126909/9430088 [00:00<00:30, 304479.79it/s]\n",
      "100%|██████████| 9430088/9430088 [00:25<00:00, 376870.45it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 378875.79it/s]\n",
      " 22%|██▏       | 2121631/9430088 [00:05<00:20, 364782.47it/s]\n",
      " 17%|█▋        | 1613960/9430088 [00:04<00:22, 344371.69it/s]\n",
      "100%|██████████| 9430088/9430088 [00:25<00:00, 375713.85it/s]\n",
      "  6%|▋         | 601514/9430088 [00:01<00:28, 314704.36it/s]\n",
      " 13%|█▎        | 1181037/9430088 [00:03<00:24, 332028.46it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 379651.13it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 377264.73it/s]\n",
      " 30%|███       | 2869363/9430088 [00:07<00:17, 369168.89it/s]\n",
      "  9%|▉         | 890701/9430088 [00:02<00:24, 343333.93it/s]\n",
      "  3%|▎         | 326007/9430088 [00:00<00:27, 330561.07it/s]\n",
      " 40%|████      | 3801012/9430088 [00:10<00:16, 350594.09it/s]\n",
      "  9%|▉         | 836246/9430088 [00:02<00:25, 332641.30it/s]\n",
      "  2%|▏         | 161142/9430088 [00:00<00:53, 174421.03it/s]\n",
      " 10%|▉         | 916730/9430088 [00:02<00:25, 334444.39it/s]\n",
      " 31%|███▏      | 2957843/9430088 [00:07<00:16, 385696.25it/s]\n",
      " 14%|█▎        | 1275281/9430088 [00:03<00:21, 383265.28it/s]\n",
      " 58%|█████▊    | 5511134/9430088 [00:15<00:10, 357011.71it/s]\n",
      "  5%|▍         | 436180/9430088 [00:01<00:33, 271662.83it/s]\n",
      " 10%|▉         | 929443/9430088 [00:02<00:24, 348369.78it/s]\n",
      "100%|██████████| 9430088/9430088 [00:26<00:00, 356189.83it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 379229.54it/s]\n",
      "  4%|▎         | 343317/9430088 [00:01<00:28, 323194.91it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 380329.86it/s]\n",
      " 46%|████▋     | 4381922/9430088 [00:12<00:13, 361330.68it/s]\n",
      "100%|██████████| 9430088/9430088 [00:25<00:00, 370057.92it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 387963.82it/s]\n",
      "  8%|▊         | 712834/9430088 [00:02<00:27, 319658.58it/s]\n",
      " 26%|██▌       | 2437814/9430088 [00:07<00:20, 343688.17it/s]\n",
      "  5%|▌         | 497405/9430088 [00:01<00:26, 339040.17it/s]\n",
      "  7%|▋         | 641444/9430088 [00:01<00:26, 327919.28it/s]\n",
      " 23%|██▎       | 2161560/9430088 [00:06<00:22, 329625.45it/s]\n",
      " 10%|█         | 956292/9430088 [00:02<00:24, 342795.31it/s]\n",
      " 25%|██▍       | 2349799/9430088 [00:06<00:19, 356548.73it/s]\n",
      " 20%|██        | 1887193/9430088 [00:05<00:22, 336150.87it/s]\n",
      " 21%|██▏       | 2009834/9430088 [00:05<00:21, 348217.73it/s]\n",
      " 61%|██████    | 5730835/9430088 [00:17<00:11, 330602.09it/s]\n",
      "  9%|▊         | 810884/9430088 [00:02<00:25, 331616.44it/s]\n",
      "  6%|▌         | 525864/9430088 [00:01<00:24, 358882.70it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 377603.66it/s]\n",
      " 13%|█▎        | 1186235/9430088 [00:03<00:24, 342506.99it/s]\n",
      " 10%|▉         | 928030/9430088 [00:02<00:24, 347578.26it/s]\n",
      " 10%|█         | 988483/9430088 [00:03<00:26, 322480.84it/s]\n",
      "100%|██████████| 9430088/9430088 [00:25<00:00, 374880.03it/s]\n",
      " 40%|████      | 3782561/9430088 [00:11<00:17, 331081.80it/s]\n",
      "100%|██████████| 9430088/9430088 [00:24<00:00, 386082.73it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2032)\n",
    "\n",
    "question = \"Which item shares over {num} co-viewed items with item {item_title}?\"\n",
    "answer = \"{item_title_neighbour}\"\n",
    "\n",
    "num = 4\n",
    "generated_data = []\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "random.shuffle(item_ids)\n",
    "\n",
    "brand_ids = list(graph['brand_nodes'].keys()) # 110796\n",
    "random.shuffle(brand_ids)\n",
    "\n",
    "for item_id in item_ids:\n",
    "    item_features= graph['item_nodes'][item_id]['features']\n",
    "    item_title = item_features['title']\n",
    "\n",
    "    if item_title=='':\n",
    "        continue\n",
    "\n",
    "    coview_item_ids = graph['item_nodes'][item_id]['neighbors']['also_viewed_item']\n",
    "    if len(coview_item_ids) < num:\n",
    "        continue\n",
    "\n",
    "    res = []\n",
    "    for search_item_id in tqdm(item_ids): \n",
    "        if (search_item_id==item_id) or (search_item_id not in graph['item_nodes']):\n",
    "            continue\n",
    "        neighbor_coview_item_ids= graph['item_nodes'][search_item_id]['neighbors']['also_viewed_item']\n",
    "        if len(neighbor_coview_item_ids)<num:\n",
    "            continue   \n",
    "        coview_item_ids_set = set(coview_item_ids)\n",
    "        neighbor_coview_item_ids_set = set(neighbor_coview_item_ids)\n",
    "        if len(coview_item_ids_set.intersection(neighbor_coview_item_ids_set))>=num:\n",
    "            neighbor_features = graph['item_nodes'][search_item_id]['features']\n",
    "            res.append(neighbor_features['title'])\n",
    "        if len(res) > 30:\n",
    "            break\n",
    "\n",
    "    if len(res) < 20 and len(res) > 0:\n",
    "        generated_data.append({\"num\":num, \"item_title\":item_title, \"item_title_neighbour\": ', '.join(res)})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9430088/9430088 [00:18<00:00, 522886.22it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 588777.92it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 597087.29it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 589662.57it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 586618.86it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 586532.46it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 577400.70it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 598090.23it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 584304.69it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 581786.26it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 585713.70it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 593577.23it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 601773.54it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 585243.25it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 583035.11it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 584807.47it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 597843.38it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 589050.88it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 586104.29it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 589691.52it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 589036.22it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 604839.99it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 589499.97it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 587332.85it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 586989.82it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 591698.17it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 599653.99it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 583173.29it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 585787.03it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 586130.41it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 600187.03it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 583294.83it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 581712.49it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 584816.03it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 582760.72it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 602121.50it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 588209.70it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 589061.28it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 591695.82it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 593368.74it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 591598.45it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 589216.89it/s]\n",
      "100%|██████████| 9430088/9430088 [00:15<00:00, 591008.20it/s]\n",
      "100%|██████████| 9430088/9430088 [00:16<00:00, 585342.42it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2033)\n",
    "\n",
    "question = \"Which item shares over {num} bought-together items with item {item_title}?\"\n",
    "answer = \"{item_title_neighbour}\"\n",
    "\n",
    "num = 4\n",
    "generated_data = []\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "random.shuffle(item_ids)\n",
    "\n",
    "brand_ids = list(graph['brand_nodes'].keys()) # 110796\n",
    "random.shuffle(brand_ids)\n",
    "\n",
    "for item_id in item_ids:\n",
    "    item_features= graph['item_nodes'][item_id]['features']\n",
    "    item_title = item_features['title']\n",
    "    \n",
    "    if item_title=='':\n",
    "        continue\n",
    "    \n",
    "    coview_item_ids = graph['item_nodes'][item_id]['neighbors']['bought_together_item']\n",
    "    if len(coview_item_ids) < num:\n",
    "        continue\n",
    "    \n",
    "    res = []\n",
    "    for search_item_id in tqdm(item_ids): \n",
    "        if (search_item_id==item_id) or (search_item_id not in graph['item_nodes']):\n",
    "            continue\n",
    "        neighbor_coview_item_ids= graph['item_nodes'][search_item_id]['neighbors']['bought_together_item']\n",
    "        if len(neighbor_coview_item_ids)<num:\n",
    "            continue   \n",
    "        coview_item_ids_set = set(coview_item_ids)\n",
    "        neighbor_coview_item_ids_set = set(neighbor_coview_item_ids)\n",
    "        if len(coview_item_ids_set.intersection(neighbor_coview_item_ids_set))>=num:\n",
    "            neighbor_features = graph['item_nodes'][search_item_id]['features']\n",
    "            res.append(neighbor_features['title'])\n",
    "        if len(res) > 30:\n",
    "            break\n",
    "\n",
    "    if len(res) < 20 and len(res) > 0:\n",
    "        generated_data.append({\"num\":num, \"item_title\":item_title, \"item_title_neighbour\": ', '.join(res)})\n",
    "  \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2034)\n",
    "\n",
    "question = \"How many items have the same bought-together items with item {item_title}?\"\n",
    "answer = \"{num}\"\n",
    "generated_data = []\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "random.shuffle(item_ids)\n",
    "\n",
    "brand_ids = list(graph['brand_nodes'].keys()) # 110796\n",
    "random.shuffle(brand_ids)\n",
    "\n",
    "for item_id in item_ids:\n",
    "    item_features= graph['item_nodes'][item_id]['features']\n",
    "    item_title = item_features['title']\n",
    "\n",
    "    if item_title=='':\n",
    "        continue\n",
    "\n",
    "    coview_item_ids = graph['item_nodes'][item_id]['neighbors']['bought_together_item']\n",
    "    \n",
    "    num_shared = 0\n",
    "    for search_item_id in item_ids: \n",
    "        if (search_item_id==item_id) or (search_item_id not in graph['item_nodes']):\n",
    "            continue\n",
    "        neighbor_coview_item_ids= graph['item_nodes'][search_item_id]['neighbors']['bought_together_item']\n",
    "\n",
    "        coview_item_ids_set = set(coview_item_ids)\n",
    "        neighbor_coview_item_ids_set = set(neighbor_coview_item_ids)\n",
    "\n",
    "        if coview_item_ids_set==neighbor_coview_item_ids_set:\n",
    "            num_shared+=1\n",
    "    \n",
    "    if num_shared>0 and num_shared<100:\n",
    "        generated_data.append({\"num\":num_shared, \"item_title\":item_title})\n",
    "    \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 14614.30it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 19784.45it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 30174.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 14266.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15768.06it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 31775.03it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 27776.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17403.75it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17403.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 33420.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 28630.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 18157.16it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 34807.50it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 29641.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 10922.67it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11748.75it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2035)\n",
    "\n",
    "question = \"What is the average price of the bought-together items with {item_title}?\"\n",
    "\n",
    "answer = \"{average_price}\"\n",
    "generated_data = []\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "random.shuffle(item_ids)\n",
    "\n",
    "\n",
    "for item_id in item_ids:\n",
    "    item_features= graph['item_nodes'][item_id]['features']\n",
    "    item_title = item_features['title']\n",
    "    \n",
    "    if item_title=='':\n",
    "        continue\n",
    "    \n",
    "    cobuy_item_ids = graph['item_nodes'][item_id]['neighbors']['bought_together_item']\n",
    "    if len(cobuy_item_ids)==0:\n",
    "        continue\n",
    "    \n",
    "    all_price=[]\n",
    "    for search_item_id in tqdm(cobuy_item_ids): \n",
    "        if search_item_id not in graph['item_nodes']:\n",
    "            continue\n",
    "        price = graph['item_nodes'][search_item_id]['features']['price']\n",
    "        if price!='':\n",
    "            all_price.append(price)\n",
    "    \n",
    "    if len(all_price)>0:\n",
    "        generated_data.append({\"item_title\":item_title, \"average_price\": round(sum(all_price)/len(all_price),2) })\n",
    "  \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 39945.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 24600.02it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 110740.70it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 31300.78it/s]\n",
      "100%|██████████| 182/182 [00:00<00:00, 171349.79it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 60787.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11814.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17050.02it/s]\n",
      "100%|██████████| 124/124 [00:00<00:00, 235443.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16912.52it/s]\n",
      "100%|██████████| 31/31 [00:00<00:00, 167988.92it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2036)\n",
    "\n",
    "question = \"What is the average price of the co-viewed items with {item_title}?\"\n",
    "\n",
    "answer = \"{average_price}\"\n",
    "generated_data = []\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "random.shuffle(item_ids)\n",
    "\n",
    "\n",
    "for item_id in item_ids:\n",
    "    item_features= graph['item_nodes'][item_id]['features']\n",
    "    item_title = item_features['title']\n",
    "    \n",
    "    if item_title=='':\n",
    "        continue\n",
    "    \n",
    "    coview_item_ids = graph['item_nodes'][item_id]['neighbors']['also_viewed_item']\n",
    "    if len(coview_item_ids)==0:\n",
    "        continue\n",
    "    \n",
    "    all_price=[]\n",
    "    for search_item_id in tqdm(coview_item_ids): \n",
    "        if search_item_id not in graph['item_nodes']:\n",
    "            continue\n",
    "        price = graph['item_nodes'][search_item_id]['features']['price']\n",
    "        if price!='':\n",
    "            all_price.append(price)\n",
    "    \n",
    "    if len(all_price)>0:\n",
    "        generated_data.append({\"item_title\":item_title, \"average_price\": round(sum(all_price)/len(all_price),2) })\n",
    "  \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 16131.94it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 33156.55it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 17772.47it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 21345.06it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 21399.51it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 22733.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12087.33it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 33825.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16513.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16448.25it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 25653.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 27594.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15534.46it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2037)\n",
    "\n",
    "question = \"What is the most popular category name of the bought-together items with {item_title}?\"\n",
    "\n",
    "answer = \"{category}\"\n",
    "generated_data = []\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "random.shuffle(item_ids)\n",
    "\n",
    "\n",
    "for item_id in item_ids:\n",
    "    item_features= graph['item_nodes'][item_id]['features']\n",
    "    item_title = item_features['title']\n",
    "    \n",
    "    if item_title=='':\n",
    "        continue\n",
    "    \n",
    "    cobuy_item_ids = graph['item_nodes'][item_id]['neighbors']['bought_together_item']\n",
    "    if len(cobuy_item_ids)==0:\n",
    "        continue\n",
    "    \n",
    "    category_counter={}\n",
    "    for search_item_id in tqdm(cobuy_item_ids): \n",
    "        if search_item_id not in graph['item_nodes']:\n",
    "            continue\n",
    "        category = graph['item_nodes'][search_item_id]['features']['category']\n",
    "        \n",
    "        if len(category)!=1: # a list with a string\n",
    "            continue\n",
    "    \n",
    "        for cate in category:\n",
    "            if cate in category_counter:\n",
    "                category_counter[cate]+=1\n",
    "            else:\n",
    "                category_counter[cate]=1\n",
    "        \n",
    "    if len(category_counter)>0:\n",
    "        most_popular_category= max(category_counter, key= lambda x: category_counter[x]) \n",
    "        generated_data.append({\"item_title\":item_title, \"category\": most_popular_category })\n",
    "  \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:00<00:00, 150976.07it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 138758.93it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 34239.22it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 68422.58it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 30690.03it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 83991.07it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 87139.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 15420.24it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 113942.18it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 119593.19it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(2038)\n",
    "\n",
    "question = \"What is the most popular category name of the co-viewed items with {item_title}?\"\n",
    "\n",
    "answer = \"{category}\"\n",
    "generated_data = []\n",
    "\n",
    "item_ids = list(graph['item_nodes'].keys())\n",
    "random.shuffle(item_ids)\n",
    "\n",
    "\n",
    "for item_id in item_ids:\n",
    "    item_features= graph['item_nodes'][item_id]['features']\n",
    "    item_title = item_features['title']\n",
    "    \n",
    "    if item_title=='':\n",
    "        continue\n",
    "    \n",
    "    coview_item_ids = graph['item_nodes'][item_id]['neighbors']['also_viewed_item']\n",
    "    if len(coview_item_ids)==0:\n",
    "        continue\n",
    "    \n",
    "    category_counter={}\n",
    "    for search_item_id in tqdm(coview_item_ids): \n",
    "        if search_item_id not in graph['item_nodes']:\n",
    "            continue\n",
    "        category = graph['item_nodes'][search_item_id]['features']['category']\n",
    "        \n",
    "        if len(category)!=1: # a list with a string\n",
    "            continue\n",
    "    \n",
    "        for cate in category:\n",
    "            if cate in category_counter:\n",
    "                category_counter[cate]+=1\n",
    "            else:\n",
    "                category_counter[cate]=1\n",
    "        \n",
    "\n",
    "    if len(category_counter)>0:\n",
    "        most_popular_category= max(category_counter, key= lambda x: category_counter[x]) \n",
    "        generated_data.append({\"item_title\":item_title, \"category\": most_popular_category })\n",
    "  \n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inductive reasoning (hard)\n",
    "### Recommendation - What item should be recommended to the user based on his history: {item_titles}?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82677131/82677131 [04:15<00:00, 323037.71it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to load reviews\n",
    "def load_reviews(file_path):\n",
    "    user_history = defaultdict(list)\n",
    "    with open(file_path, 'r') as f:\n",
    "        readin = f.readlines()\n",
    "        for line in tqdm(readin):\n",
    "            tmp = line.strip().split(',')\n",
    "            user_history[tmp[0]].append((tmp[-1], tmp[1]))\n",
    "    return user_history\n",
    "\n",
    "# Load and preprocess reviews\n",
    "user_history = load_reviews('/shared/data3/bowenj4/llm-graph-plugin/data/raw_data/amazon/item_dedup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2039)\n",
    "\n",
    "question = \"What next item should be recommended to the user based on his history: {item_titles}?\"\n",
    "answer = \"{targe_item_title}\"\n",
    "generated_data = []\n",
    "\n",
    "user_ids = list(user_history.keys())\n",
    "random.shuffle(user_ids)\n",
    "\n",
    "for user_id in user_ids:\n",
    "    tmp_history = user_history[user_id]\n",
    "    tmp_history.sort(key=lambda x: x[0])\n",
    "    \n",
    "    if len(tmp_history) < 2 or tmp_history[-1][-1] not in graph['item_nodes'] or graph['item_nodes'][tmp_history[-1][-1]]['features']['title'] == '':\n",
    "        continue\n",
    "\n",
    "    item_titles = [graph['item_nodes'][idd[-1]]['features']['title'] for idd in tmp_history[-8:-1] if idd[-1] in graph['item_nodes'] and graph['item_nodes'][idd[-1]]['features']['title'] != '']\n",
    "    targe_item_title = graph['item_nodes'][tmp_history[-1][-1]]['features']['title']\n",
    "\n",
    "    if targe_item_title != '' and len(item_titles) >= 5:\n",
    "        generated_data.append({\"item_titles\": item_titles, \"targe_item_title\": targe_item_title})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval - What is the exact matched/substitute/complement item given this query: {item_titles}?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_examples = pd.read_parquet('/shared/data3/bowenj4/llm-graph-plugin/data/raw_data/amazon/shopping_queries_dataset/shopping_queries_dataset_examples.parquet')\n",
    "df_products = pd.read_parquet('/shared/data3/bowenj4/llm-graph-plugin/data/raw_data/amazon/shopping_queries_dataset/shopping_queries_dataset_products.parquet')\n",
    "df_examples_products = pd.merge(\n",
    "    df_examples,\n",
    "    df_products,\n",
    "    how='left',\n",
    "    left_on=['product_locale','product_id'],\n",
    "    right_on=['product_locale', 'product_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_ids = set(list(graph['item_nodes'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_task_2 = df_examples_products[df_examples_products[\"large_version\"] == 1]\n",
    "df_task_2_train = df_task_2[df_task_2[\"split\"] == \"train\"]\n",
    "df_task_2_test = df_task_2[df_task_2[\"split\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact match\n",
    "np.random.seed(2040)\n",
    "\n",
    "question = \"What is the exact matched item given this query: {query_text}?\"\n",
    "answer = \"{targe_item_title}\"\n",
    "generated_data = []\n",
    "\n",
    "## Exact match\n",
    "df_em = df_task_2_test[df_task_2_test[\"esci_label\"] == \"E\"]\n",
    "\n",
    "# shuffle the DataFrame rows\n",
    "df_em = df_em.sample(frac = 1)\n",
    "\n",
    "# process\n",
    "for _, row in df_em.iterrows():\n",
    "    cnt = len(df_em[(df_em.query_id == row['query_id'])])\n",
    "\n",
    "    if row['product_locale'] == 'us' and cnt == 1 and row['product_id'] in prod_ids:\n",
    "        #generated_data.append({\"query_text\": row['query'], \"targe_item_title\": row['product_title']})\n",
    "        generated_data.append({\"query_text\": row['query'], \"targe_item_title\": graph['item_nodes'][row['product_id']]['features']['title']})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitutive\n",
    "np.random.seed(2041)\n",
    "\n",
    "question = \"What is the substitutive item given this query: {query_text}?\"\n",
    "answer = \"{targe_item_title}\"\n",
    "generated_data = []\n",
    "\n",
    "## Exact match\n",
    "df_em = df_task_2_test[df_task_2_test[\"esci_label\"] == \"S\"]\n",
    "\n",
    "# shuffle the DataFrame rows\n",
    "df_em = df_em.sample(frac = 1)\n",
    "\n",
    "# process\n",
    "for _, row in df_em.iterrows():\n",
    "    cnt = len(df_em[(df_em.query_id == row['query_id'])])\n",
    "\n",
    "    if row['product_locale'] == 'us' and cnt == 1 and row['product_id'] in prod_ids:\n",
    "        #generated_data.append({\"query_text\": row['query'], \"targe_item_title\": row['product_title']})\n",
    "        generated_data.append({\"query_text\": row['query'], \"targe_item_title\": graph['item_nodes'][row['product_id']]['features']['title']})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complementary\n",
    "np.random.seed(2042)\n",
    "\n",
    "question = \"What is the complementary item given this query: {query_text}?\"\n",
    "answer = \"{targe_item_title}\"\n",
    "generated_data = []\n",
    "\n",
    "## Exact match\n",
    "df_em = df_task_2_test[df_task_2_test[\"esci_label\"] == \"C\"]\n",
    "\n",
    "# shuffle the DataFrame rows\n",
    "df_em = df_em.sample(frac = 1)\n",
    "\n",
    "# process\n",
    "for _, row in df_em.iterrows():\n",
    "    cnt = len(df_em[(df_em.query_id == row['query_id'])])\n",
    "\n",
    "    if row['product_locale'] == 'us' and cnt == 1 and row['product_id'] in prod_ids:\n",
    "        #generated_data.append({\"query_text\": row['query'], \"targe_item_title\": row['product_title']})\n",
    "        generated_data.append({\"query_text\": row['query'], \"targe_item_title\": graph['item_nodes'][row['product_id']]['features']['title']})\n",
    "\n",
    "    if len(generated_data) == k:\n",
    "        break\n",
    "\n",
    "all_generated_data[(question, answer)] = generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "pickle.dump(all_generated_data, open(os.path.join(f'preprocess_samples.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(all_generated_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
